{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyOIoN6HmVNoQh3nZDNei23r",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Bryce-R/ML/blob/master/SimpleDecoderTransformer.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Voi5WUKxpgFs"
      },
      "outputs": [],
      "source": [
        "# !pip install wandb\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import random\n",
        "import matplotlib.pyplot as plt\n",
        "import math\n",
        "from tqdm.auto import tqdm\n",
        "# import wandb\n",
        "\n",
        "# set random seed\n",
        "random.seed(42)\n",
        "torch.manual_seed(42)\n",
        "\n",
        "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
        "print(f\"Using device \", device)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class DecoderBlock(nn.Module):\n",
        "    def __init__(self, d_model, n_heads, d_ff):\n",
        "        super().__init__()\n",
        "        self.self_attn = nn.MultiheadAttention(d_model, n_heads, batch_first=True)\n",
        "        self.ln1 = nn.LayerNorm(d_model)\n",
        "        self.ff = nn.Sequential(\n",
        "            nn.Linear(d_model, d_ff),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(d_ff, d_model),\n",
        "        )\n",
        "        self.ln2 = nn.LayerNorm(d_model)\n",
        "\n",
        "    def forward(self, x, mask=None):\n",
        "        # Casual self-attention\n",
        "        attn_out, _ = self.self_attn(x, x, x, attn_mask=mask)\n",
        "        x = self.ln1(x + attn_out)\n",
        "\n",
        "        ff_out = self.ff(x)\n",
        "        x = self.ln2(x + ff_out)\n",
        "        return x\n",
        "\n",
        "\n",
        "class TinyDecoderOnlyTransformer(nn.Module):\n",
        "    def __init__(self, vocab_size, d_model=256, n_heads=4, d_ff=1024, n_layers=4, seq_len=2048):\n",
        "        super().__init__()\n",
        "        self.vocab_size = vocab_size # Store vocab_size\n",
        "        self.seq_len = seq_len # Store seq_len\n",
        "        self.token_emb = nn.Embedding(vocab_size, d_model)\n",
        "        self.pos_emb = nn.Embedding(seq_len, d_model)\n",
        "\n",
        "        self.blocks = nn.ModuleList([\n",
        "            DecoderBlock(d_model, n_heads, d_ff) for _ in range(n_layers)\n",
        "        ])\n",
        "\n",
        "        self.ln_f = nn.LayerNorm(d_model)\n",
        "        self.head = nn.Linear(d_model, vocab_size, bias=False)\n",
        "\n",
        "    def forward(self, idx):\n",
        "        B, T = idx.shape\n",
        "        pos = torch.arange(T, device=idx.device)\n",
        "        x = self.token_emb(idx) + self.pos_emb(pos)\n",
        "\n",
        "        # Causal mask: (T, T)\n",
        "        mask = torch.triu(torch.ones(T, T, device=idx.device), diagonal=1)\n",
        "        mask = mask.masked_fill(mask == 1, float('-inf'))\n",
        "        # print(f\"mask\", mask)\n",
        "\n",
        "        for block in self.blocks:\n",
        "            x = block(x, mask)\n",
        "\n",
        "        x = self.ln_f(x)\n",
        "        logits = self.head(x)\n",
        "        return logits\n",
        "\n",
        "    @torch.no_grad()\n",
        "    def generate(self, idx, max_new_tokens):\n",
        "        # idx is (B, T)\n",
        "        for _ in range(max_new_tokens):\n",
        "            # Crop idx to the last seq_len tokens if it exceeds\n",
        "            idx_cond = idx if idx.shape[1] <= self.seq_len else idx[:, -self.seq_len:]\n",
        "\n",
        "            # Get predictions\n",
        "            logits = self(idx_cond)\n",
        "            # Focus only on the last time step\n",
        "            logits = logits[:, -1, :]\n",
        "            # Apply softmax to get probabilities\n",
        "            # probs = F.softmax(logits, dim=-1)\n",
        "            # Sample the next token with highest probability (greedy sampling)\n",
        "            # idx_next = torch.multinomial(probs, num_samples=1)\n",
        "            idx_next = torch.argmax(logits, dim=-1, keepdim=True)\n",
        "\n",
        "            # Append sampled index to the running sequence\n",
        "            idx = torch.cat((idx, idx_next), dim=1)\n",
        "        return idx\n"
      ],
      "metadata": {
        "id": "0LGkW1OpqOJ9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "bguEs6m-iXFC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Example usage\n",
        "vocab = 50\n",
        "model = TinyDecoderOnlyTransformer(vocab, d_model=8, n_heads=4, d_ff=32, n_layers=2)\n",
        "# model = TinyDecoderOnlyTransformer(vocab, d_model=128, n_heads=4, d_ff=512, n_layers=2)\n",
        "model.to(device)\n",
        "idx = torch.randint(0, vocab, (2, 10), device=device)  # batch=2, seq_len=32\n",
        "logits = model(idx)\n",
        "print(logits.shape)  # (2, 32, vocab)\n"
      ],
      "metadata": {
        "id": "WTIPUAETqRqR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def plot_sequence(sequence):\n",
        "    velocity = sequence[:, 0]\n",
        "    time = torch.arange(sequence.size(0)) * 0.5\n",
        "\n",
        "    plt.figure(figsize=(10, 4))\n",
        "    plt.plot(time, velocity, label='Velocity (m/s)')\n",
        "    plt.xlabel('Time (s)')\n",
        "    plt.ylabel('Velocity')\n",
        "    plt.title('Velocity over Time')\n",
        "    plt.legend()\n",
        "    plt.grid(True)\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "def generate_velocity_sequence(seq_length):\n",
        "\n",
        "    velocity = 0.0\n",
        "    sequence = [ [velocity] ]\n",
        "    state = 'up'  # 'up', 'down', 'stop'\n",
        "    stop_counter = 0\n",
        "\n",
        "    for _ in range(seq_length):\n",
        "        if state == 'up':\n",
        "            velocity += 0.5\n",
        "            if velocity >= 10.0:\n",
        "                velocity = 10.0\n",
        "                state = 'down'\n",
        "        elif state == 'down':\n",
        "            velocity -= 0.25\n",
        "            if velocity <= 0.0:\n",
        "                velocity = 0.0\n",
        "                state = 'stop'\n",
        "                stop_counter = 0\n",
        "        elif state == 'stop':\n",
        "            stop_counter += 1\n",
        "            if stop_counter >= 2:\n",
        "                state = 'up'\n",
        "\n",
        "        sequence.append([velocity])\n",
        "\n",
        "    return torch.tensor(sequence, dtype=torch.float32)\n",
        "\n",
        "\n",
        "# x = generate_velocity_sequence(500).unsqueeze(0)  # Single sequence of length 50\n",
        "x = generate_velocity_sequence(500).unsqueeze(0)  # Single sequence of length 50\n",
        "# Plot the sequence\n",
        "plot_sequence(x[0]) # [B, T, dim]\n",
        "print(x.shape)"
      ],
      "metadata": {
        "id": "IYXqkeYBiXmT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class VelocityTokenizer:\n",
        "    def __init__(self, min_val=0.0, max_val=10.0, vocab_size=50):\n",
        "        self.min_val = min_val\n",
        "        self.max_val = max_val\n",
        "        self.vocab_size = vocab_size\n",
        "        # Calculate bin width to include both min and max values within the vocab_size range\n",
        "        self.bin_width = (max_val - min_val) / (vocab_size - 1)\n",
        "\n",
        "    def tokenize(self, velocity_sequence):\n",
        "        # Ensure values are within min_val and max_val\n",
        "        clipped_sequence = torch.clamp(velocity_sequence, self.min_val, self.max_val)\n",
        "        # Scale to 0 to (vocab_size - 1) range\n",
        "        scaled_sequence = (clipped_sequence - self.min_val) / self.bin_width\n",
        "        # Round to nearest integer and convert to long for token IDs\n",
        "        tokens = torch.round(scaled_sequence).long()\n",
        "        return tokens\n",
        "\n",
        "    def detokenize(self, tokens):\n",
        "        # Convert tokens back to scaled values\n",
        "        scaled_values = tokens.float() * self.bin_width + self.min_val\n",
        "        return scaled_values\n",
        "\n",
        "# Example usage with the generated sequence 'x'\n",
        "# 'vocab' variable is already defined globally in your notebook as 50\n",
        "vocab = 50\n",
        "tokenizer = VelocityTokenizer(vocab_size=vocab)\n",
        "\n",
        "# Tokenize the velocity sequence 'x'\n",
        "tokenized_x = tokenizer.tokenize(x)\n",
        "\n",
        "# Squeeze the last dimension to match the transformer's expected input shape (B, T)\n",
        "tokenized_x_for_transformer = tokenized_x.squeeze(-1)\n",
        "\n",
        "print(f\"Original sequence shape: {x.shape}\")\n",
        "print(f\"Tokenized sequence shape: {tokenized_x.shape}\")\n",
        "print(f\"Tokenized sequence for transformer shape (B, T): {tokenized_x_for_transformer.shape}\")\n",
        "print(f\"First 10 original velocity values (batch 0):\")\n",
        "for i in range(10):\n",
        "    print(f\"  {x[0, i, 0].item():.2f}\")\n",
        "print(f\"First 10 tokenized values (batch 0):\")\n",
        "print(f\"  {tokenized_x_for_transformer[0, :10].tolist()}\")\n",
        "\n",
        "print(f\"Maximum token value: {tokenized_x_for_transformer.max().item()}\")\n",
        "print(f\"Minimum token value: {tokenized_x_for_transformer.min().item()}\")\n",
        "\n",
        "# Verify detokenization (optional, for checking accuracy)\n",
        "detokenized_x = tokenizer.detokenize(tokenized_x)\n",
        "print(f\"\\nDetokenized sequence shape: {detokenized_x.shape}\")\n",
        "print(f\"Original vs Detokenized (first 10 values, batch 0):\")\n",
        "for i in range(10):\n",
        "    print(f\"  Original: {x[0, i, 0].item():.2f}, Detokenized: {detokenized_x[0, i, 0].item():.2f}\")\n"
      ],
      "metadata": {
        "id": "FKFK-jd8sqDv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "DzpeW41s5P4w"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import time\n",
        "\n",
        "seq_len = 30\n",
        "model = TinyDecoderOnlyTransformer(vocab, d_model=8, n_heads=4, d_ff=32, n_layers=4, seq_len=seq_len)\n",
        "model.to(device)\n",
        "history_len = 10\n",
        "step = 50\n",
        "# x [B, 501, 1]\n",
        "loss = nn.CrossEntropyLoss()\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
        "\n",
        "chunk_step = 20\n",
        "\n",
        "loss_values = []\n",
        "steps = []\n",
        "\n",
        "train_index = int(x.shape[1]*0.9)\n",
        "\n",
        "start_time = time.time() # Start timer\n",
        "\n",
        "for epoch in tqdm(range(200)):\n",
        "  for i in range(0, train_index-seq_len-1, chunk_step):\n",
        "      x_batch = x[:, i:i+seq_len, :].to(device)\n",
        "      y_batch = x[:, i+1:i+seq_len+1, :].to(device)\n",
        "      tokenized_x_batch = tokenizer.tokenize(x_batch)\n",
        "      tokenized_x_batch_for_transformer = tokenized_x_batch.squeeze(-1)\n",
        "      tokenized_y_batch = tokenizer.tokenize(y_batch)\n",
        "      tokenized_y_batch = tokenized_y_batch.squeeze(-1)\n",
        "      logits = model(tokenized_x_batch_for_transformer)\n",
        "      loss_value = loss(logits.view(-1, logits.shape[-1]), tokenized_y_batch.view(-1))\n",
        "      optimizer.zero_grad()\n",
        "      loss_value.backward()\n",
        "      optimizer.step()\n",
        "      loss_values.append(loss_value.item())\n",
        "      if len(steps) == 0:\n",
        "        steps.append(0)\n",
        "      else:\n",
        "        steps.append(steps[-1] + 1)\n",
        "      if epoch % 10 == 0 and i == 0:\n",
        "        print(f\"Epoch {epoch}, Step {i}, Loss {loss_value.item()}\")\n",
        "\n",
        "end_time = time.time() # End timer\n",
        "elapsed_time = end_time - start_time\n",
        "print(f\"Training completed in {elapsed_time:.2f} seconds.\")\n",
        "\n",
        "plt.figure(figsize=(10, 4))\n",
        "plt.plot(steps, loss_values, label='Loss')\n",
        "plt.grid()"
      ],
      "metadata": {
        "id": "5PYUc4Wo4qKY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Calculate Validation Loss\n",
        "model.eval() # Set model to evaluation mode\n",
        "val_loss_values = []\n",
        "\n",
        "with torch.no_grad(): # Disable gradient calculation for validation\n",
        "    # Validation data starts from train_index\n",
        "    val_data = x[:, train_index:, :].to(device)\n",
        "\n",
        "    # Make sure val_data has enough length for at least one sequence\n",
        "    if val_data.shape[1] > seq_len:\n",
        "        for i in range(0, val_data.shape[1] - seq_len - 1, chunk_step):\n",
        "            val_x_batch = val_data[:, i:i+seq_len, :]\n",
        "            val_y_batch = val_data[:, i+1:i+seq_len+1, :]\n",
        "\n",
        "            tokenized_val_x_batch = tokenizer.tokenize(val_x_batch).squeeze(-1)\n",
        "            tokenized_val_y_batch = tokenizer.tokenize(val_y_batch).squeeze(-1)\n",
        "\n",
        "            logits = model(tokenized_val_x_batch)\n",
        "            val_loss_value = loss(logits.view(-1, logits.shape[-1]), tokenized_val_y_batch.view(-1))\n",
        "            val_loss_values.append(val_loss_value.item())\n",
        "\n",
        "if len(val_loss_values) > 0:\n",
        "    avg_val_loss = sum(val_loss_values) / len(val_loss_values)\n",
        "    print(f\"Average Validation Loss: {avg_val_loss:.4f}\")\n",
        "else:\n",
        "    print(\"Not enough data for validation or validation loop was not executed.\")\n",
        "\n",
        "# model.train() # Set model back to training mode"
      ],
      "metadata": {
        "id": "S--IWUyTX67h"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "start = 5\n",
        "end = 10\n",
        "for start in [5, 10, 20, 25, 50]:\n",
        "    end = start + 5\n",
        "    history = x[:, start:end, :]\n",
        "    # print(f\"history\", history)\n",
        "    tokenized_idx = tokenizer.tokenize(history).squeeze(-1).to(device)\n",
        "    # print(f\"tokenized_idx\", tokenized_idx)\n",
        "    # print(f\"tokenized_idx.shape\", tokenized_idx.shape)\n",
        "    sequence = model.generate(tokenized_idx, seq_len-history.shape[1])\n",
        "    # print(f\"sequence\", sequence)\n",
        "    detokenized_sequence = tokenizer.detokenize(sequence)\n",
        "    # print(f\"detokenized_sequence\", detokenized_sequence.cpu().numpy()[0][5:])\n",
        "\n",
        "    plt.figure(figsize=(10, 4))\n",
        "    plt.plot(history.cpu().numpy()[0], label='history')\n",
        "    plt.plot(range(end-start, start+seq_len-start),x[:, end:start+seq_len, :].cpu().numpy()[0], label='GT')\n",
        "    plt.plot(detokenized_sequence.cpu().numpy()[0], '--', label='Prediction')\n",
        "    plt.grid()\n",
        "    plt.legend()\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "fUJTtTQJMw7t"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(model.token_emb.weight.shape) # vocab_size, d_model\n",
        "print(model.token_emb.weight[:1, :])\n",
        "d_model = model.token_emb.weight.shape[1]\n",
        "\n",
        "plt.figure(figsize=(8, 6))\n",
        "for i in range(model.vocab_size):\n",
        "  plt.plot([i]*d_model, model.token_emb.weight[i].cpu().detach().numpy(), '+' ,label=f'Token {i}')\n",
        "# plt.legend()\n",
        "plt.grid()\n",
        "plt.xlabel(\"token ID\")\n",
        "\n",
        "plt.figure(figsize=(8, 6))\n",
        "for i in range(d_model):\n",
        "  plt.plot(model.token_emb.weight[:,i].cpu().detach().numpy(), '.--' ,label=f'Token {i}')\n",
        "# plt.legend()\n",
        "plt.grid()\n",
        "plt.xlabel(\"token ID\")"
      ],
      "metadata": {
        "id": "Zdkp65hUntOS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Calculate and plot cosine similarity between token embeddings\n",
        "embeddings = model.token_emb.weight.cpu().detach()\n",
        "cosine_similarity_matrix = torch.nn.functional.cosine_similarity(embeddings.unsqueeze(1), embeddings.unsqueeze(0), dim=-1)\n",
        "\n",
        "plt.figure(figsize=(15, 12))\n",
        "plt.imshow(cosine_similarity_matrix.numpy(), cmap='viridis')\n",
        "plt.colorbar(label='Cosine Similarity')\n",
        "plt.title('Cosine Similarity Matrix of Token Embeddings')\n",
        "plt.xlabel('Token ID')\n",
        "plt.ylabel('Token ID')\n",
        "plt.xticks(range(model.vocab_size))\n",
        "plt.yticks(range(model.vocab_size))\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "NBvAIiKnsX2R"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "k5-AOsKdn-3h"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}